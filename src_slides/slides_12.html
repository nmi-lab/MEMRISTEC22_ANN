<section>
        <section data-markdown data-vertical-align-top data-background-color=#B2BA67><textarea data-template>
            <h1> Lecture 12: Memristor Models in PyTorch<br/> </h1>
            <ul>
              <li/> Slides derived from <a href='https://aihwkit.readthedocs.io/'>AIHWKIT Documentation</a>
        </textarea></section>

      <section data-markdown><textarea data-template>
      <h2> Memristor Introduction</h2>                                                     
      <img src="img/" />
      <ul>
        <li class="fragment"/> 
      </ul>
      </textarea></section>

      <section data-markdown><textarea data-template>
      <h2> In-Memory Computing</h2>                                                     
      <img src="img/analog_chip_description.png" />
      <ul>
        <li class="fragment"/> Multiple crossbar arrays that communicate with each other
        <li class="fragment"/> Efficient vector-matrix multiplication
          <li class="fragment"/> <b>Offchip Training:</b> weights are typically trained using a conventional GPU-based hardware and transferred
        <li class="fragment"/>   <b>Onchip Training: </b>weights are typically trained using a conventional GPU-based hardware and transferred
      </ul>
      </textarea></section>

      <section data-markdown><textarea data-template>
      <h2> Memristor Typees and Non-Idealities</h2>                                                     
      <img src="img/analog_ai_hw.png" class="large"/>
      <ul>
        <li class="fragment"/> 
      </ul>
      </textarea></section>

      <section data-markdown><textarea data-template>
      <h2> RRAM Non-Idealities</h2>                                                     
      <img src="img/asymmetry_memristor.png" />
      <p class=ref>(Spiga and Menzel, 2021)</p>
      <ul>
        <li class="fragment"/> 
      </ul>
      </textarea></section>

      <section data-markdown><textarea data-template>
      <h2> Memristor Non-Idealities</h2>                                                     
      <div class=row>
      <div class=column>
      <p>Aymmetric non-linearity</p>
      <img src="img/Agarwal_etal16_asymmetry_memristor_model1.png" class="medium"/>
      </div>
      <div class=column>

      <p>Effects of aymmetric non-linearity</p>
      <img src="img/Agarwal_etal16_asymmetric_memristor_figure2.png" class="large" />
      </div>
      </div>
      <p class=ref>[Agarwal_etal16_resimemo]</p>
      <div class=row>
      <div class=column>
        <p>Cycle to cycle non-linearity</p>
      <img src="img/analog_non_idealities.png" class="medium"/>
      </div>
      <div class=column>
        <p>Device to Device non-linearity</p>
      <img src="img/" class="medium"/>
      </div>
      </div>
      <ul>
        <li class="fragment"/> It is necessary to take these non-idealities into account during training
      </ul>
      </textarea></section>

      <section data-markdown><textarea data-template>
      <h2> Specialized Update Algorithms</h2>                                                     
      <img src="img/toolkit_quantization.png" />
      <ul>
        <li class="fragment"/>       </ul>
      </textarea></section>

      <section data-markdown><textarea data-template>
      <h2> Specialized Update Algorithms</h2>                                                     
      <p class="ref">(Rasch et al. 2021)</p>
      <ul>
        <li class="fragment"/>       </ul>
      </textarea></section>

      <section data-markdown><textarea data-template>
      <h2> A Model of a Non-linear Device </h2>                                                     
      <ul>
        <li/> $$ TBD $$
      </ul>
      </textarea></section>

      <section data-markdown><textarea data-template>
      <h2> Custom Dynamics in pure PyTorch</h2>                                                     
      <ul>
        <li/> 
      </ul>
      </textarea></section>

      <section data-markdown><textarea data-template>
      <h2> Custom Updates in pure PyTorch</h2>                                                     
      <ul>
        <li/> Recall that updates $$w \leftarrow w -\eta \nabla_w \mathcal{L}$$ are applied at the optimizer.step(). 
        <li/> So we need to create a custom optimizer
        <li/> TBD: code for custom optimizer
      </ul>
      </textarea></section>

      <section data-markdown><textarea data-template>
      <h2> AI Kardware Kit</h2>                                                     
      <div class=row>
        <div class=column>
        <img src="img/reram_measurements.png" />
        </div>
        <div class=column>
        <img src="img/reram_measurements.png" />
        </div>
      </div>
      <p class="ref">(Rasch et al. 2021)</p>
      <ul>
        <li class="fragment"/> aihwkit: Acceleration of training of crossbar arrays using PyTorch and GPUs.
        <li/> Functional simulator of forward and barckward pass (for online training)
      </ul>
      </textarea></section>

      <section data-markdown><textarea data-template>
      <h2> Specialized Update Algorithms</h2>                                                     
      <img src="img/analog_dnn_training.png"/>
      <p class="ref">(Rasch et al. 2021)</p>
      <ul>
        <li class="fragment"/> The range of the weights are limited because of the physical implementation details and hardware limitations $\rightarrow$ Quantization
      </ul>
      </textarea></section>

      <section data-markdown><textarea data-template>
      <h2> Device configuration with aihwkit: RPUConfig</h2>                                                     
      <ul>
        <li class="fragment"/> 
      </ul>
      </textarea></section>

      <section data-markdown><textarea data-template>
      <h2> Optimizer with aihwkit:AnalogSGD </h2>                                                     
      <ul>
        <li class="fragment"/> 
      </ul>
      </textarea></section>

 


 
</section>
